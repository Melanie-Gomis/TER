{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ad42a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INSTALLATIONS ET IMPORTS ---\n",
    "try:\n",
    "    import gdown\n",
    "except ImportError:\n",
    "    import os\n",
    "    os.system(\"pip install -q gdown\")\n",
    "    import gdown\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d796b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Le dossier 'redshift' est d√©j√† pr√©sent. Pas besoin de ret√©l√©charger !\n",
      "\n",
      "Succ√®s ! 17 fichiers trouv√©s dans 'redshift'.\n",
      "D√©tail des fichiers :\n",
      "[redshift] :\t XMM_LSS_v11_uijk_0177_spec_UD.npz\n",
      "[redshift] :\t info2.csv\n",
      "[redshift] :\t info3.csv\n",
      "[redshift] :\t XMM_LSS_v11_uijk_0006_spec_D.npz\n",
      "[redshift] :\t info4.csv\n",
      "[redshift] :\t cnn_photoz_model.h5\n",
      "[redshift] :\t tmp_csv\n",
      "[redshift] :\t XMM_LSS_v11_uijk_0162_phot_UD.npz\n",
      "[redshift] :\t output_zphot_only.txt\n",
      "[redshift] :\t COSMOS_v11_uijk_0073_spec_UD.npz\n",
      "[redshift] :\t XMM_LSS_v11_uijk_0162_phot_D.npz\n",
      "[redshift] :\t cnn_architecture.png\n",
      "[redshift] :\t COSMOS_v11_uijk_0020_spec_D.npz\n",
      "[redshift] :\t COSMOS_v11_uijk_0001_photo_D.npz\n",
      "[redshift] :\t best_photoz_model.pt\n",
      "[redshift] :\t COSMOS_v11_uijk_0213_photo_UD.npz\n",
      "[redshift] :\t info.csv\n",
      "\n",
      "--- INSPECTION APPROFONDIE DE 'redshift' ---\n",
      "üìÑ TROUV√â : redshift/XMM_LSS_v11_uijk_0177_spec_UD.npz | Taille : 1923288 octets\n",
      "üìÑ TROUV√â : redshift/info2.csv | Taille : 4008 octets\n",
      "üìÑ TROUV√â : redshift/info3.csv | Taille : 5217 octets\n",
      "üìÑ TROUV√â : redshift/XMM_LSS_v11_uijk_0006_spec_D.npz | Taille : 1184118 octets\n",
      "üìÑ TROUV√â : redshift/info4.csv | Taille : 118770 octets\n",
      "üìÑ TROUV√â : redshift/cnn_photoz_model.h5 | Taille : 27593632 octets\n",
      "üìÑ TROUV√â : redshift/XMM_LSS_v11_uijk_0162_phot_UD.npz | Taille : 810662442 octets\n",
      "üìÑ TROUV√â : redshift/output_zphot_only.txt | Taille : 1552218 octets\n",
      "üìÑ TROUV√â : redshift/COSMOS_v11_uijk_0073_spec_UD.npz | Taille : 1775490 octets\n",
      "üìÑ TROUV√â : redshift/XMM_LSS_v11_uijk_0162_phot_D.npz | Taille : 934811082 octets\n",
      "üìÑ TROUV√â : redshift/cnn_architecture.png | Taille : 171859 octets\n",
      "üìÑ TROUV√â : redshift/COSMOS_v11_uijk_0020_spec_D.npz | Taille : 2219001 octets\n",
      "üìÑ TROUV√â : redshift/COSMOS_v11_uijk_0001_photo_D.npz | Taille : 1781534366 octets\n",
      "üìÑ TROUV√â : redshift/best_photoz_model.pt | Taille : 30865555 octets\n",
      "üìÑ TROUV√â : redshift/COSMOS_v11_uijk_0213_photo_UD.npz | Taille : 65475010 octets\n",
      "üìÑ TROUV√â : redshift/info.csv | Taille : 3167779 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/XMM_LSS_v11_uijk_0177_spec_UD_flag.csv | Taille : 234 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/COSMOS_v11_uijk_0213_photo_UD_info.csv | Taille : 117679 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/XMM_LSS_v11_uijk_0162_phot_UD_info.csv | Taille : 1479584 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/COSMOS_v11_uijk_0020_spec_D_flag.csv | Taille : 270 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/XMM_LSS_v11_uijk_0006_spec_D_flag.csv | Taille : 144 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/COSMOS_v11_uijk_0073_spec_UD_cube.csv | Taille : 4126585 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/XMM_LSS_v11_uijk_0006_spec_D_cube.csv | Taille : 2661179 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/XMM_LSS_v11_uijk_0006_spec_D_info.csv | Taille : 2562 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/XMM_LSS_v11_uijk_0177_spec_UD_info.csv | Taille : 4383 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/COSMOS_v11_uijk_0001_photo_D_flag.csv | Taille : 216972 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/XMM_LSS_v11_uijk_0162_phot_D_flag.csv | Taille : 113850 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/COSMOS_v11_uijk_0073_spec_UD_info.csv | Taille : 3741 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/XMM_LSS_v11_uijk_0162_phot_D_info.csv | Taille : 1706789 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/COSMOS_v11_uijk_0073_spec_UD_flag.csv | Taille : 216 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/COSMOS_v11_uijk_0213_photo_UD_flag.csv | Taille : 7974 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/COSMOS_v11_uijk_0001_photo_D_info.csv | Taille : 3143466 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/COSMOS_v11_uijk_0020_spec_D_cube.csv | Taille : 4344541 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/XMM_LSS_v11_uijk_0177_spec_UD_cube.csv | Taille : 5391706 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/COSMOS_v11_uijk_0020_spec_D_info.csv | Taille : 4944 octets\n",
      "üìÑ TROUV√â : redshift/tmp_csv/XMM_LSS_v11_uijk_0162_phot_UD_flag.csv | Taille : 98730 octets\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. T√âL√âCHARGEMENT ET INSPECTION\n",
    "# ==========================================\n",
    "\n",
    "dossier_nom = \"redshift\"\n",
    "url = \"https://drive.google.com/drive/folders/1-tQH6rfB1XoF7ml98yqVn7Z2IQwGMUdK?usp=sharing\"\n",
    "\n",
    "if os.path.exists(dossier_nom):\n",
    "    print(f\"‚úÖ Le dossier '{dossier_nom}' est d√©j√† pr√©sent. Pas besoin de ret√©l√©charger !\")\n",
    "else:\n",
    "    print(f\"üì• Dossier introuvable. T√©l√©chargement en cours...\")\n",
    "    gdown.download_folder(url, quiet=False, use_cookies=False)\n",
    "    print(\"‚úÖ T√©l√©chargement termin√© !\")\n",
    "\n",
    "pattern = os.path.join(dossier_nom, \"*\")\n",
    "dossier_local = glob.glob(pattern)\n",
    "\n",
    "print(f\"\\nSucc√®s ! {len(dossier_local)} fichiers trouv√©s dans '{dossier_nom}'.\")\n",
    "print(\"D√©tail des fichiers :\")\n",
    "\n",
    "for chemin in dossier_local:\n",
    "    dossier = os.path.dirname(chemin)\n",
    "    fichier = os.path.basename(chemin)\n",
    "    print(f\"[{dossier}] :\\t {fichier}\")\n",
    "\n",
    "print(\"\\n--- INSPECTION APPROFONDIE DE 'redshift' ---\")\n",
    "dossier_cible = \"redshift\"\n",
    "est_vide = True\n",
    "\n",
    "for root, dirs, files in os.walk(dossier_cible):\n",
    "    for name in files:\n",
    "        est_vide = False\n",
    "        chemin_complet = os.path.join(root, name)\n",
    "        taille = os.path.getsize(chemin_complet)\n",
    "        print(f\"üìÑ TROUV√â : {chemin_complet} | Taille : {taille} octets\")\n",
    "\n",
    "if est_vide:\n",
    "    print(\"‚ö†Ô∏è LE DOSSIER EST VIDE.\")\n",
    "    print(\"Cela veut dire que Google a bloqu√© le t√©l√©chargement du contenu.\")\n",
    "    print(\"Solution : V√©rifie que les fichiers DANS le dossier Drive sont aussi en 'Public'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a95dab9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Fichiers .npz trouv√©s (8):\n",
      "  1. redshift/XMM_LSS_v11_uijk_0177_spec_UD.npz\n",
      "  2. redshift/XMM_LSS_v11_uijk_0006_spec_D.npz\n",
      "  3. redshift/XMM_LSS_v11_uijk_0162_phot_UD.npz\n",
      "  4. redshift/COSMOS_v11_uijk_0073_spec_UD.npz\n",
      "  5. redshift/XMM_LSS_v11_uijk_0162_phot_D.npz\n",
      "  6. redshift/COSMOS_v11_uijk_0020_spec_D.npz\n",
      "  7. redshift/COSMOS_v11_uijk_0001_photo_D.npz\n",
      "  8. redshift/COSMOS_v11_uijk_0213_photo_UD.npz\n",
      "\n",
      "Fichiers COSMOS (4):\n",
      "  1. redshift/COSMOS_v11_uijk_0073_spec_UD.npz\n",
      "  2. redshift/COSMOS_v11_uijk_0020_spec_D.npz\n",
      "  3. redshift/COSMOS_v11_uijk_0001_photo_D.npz\n",
      "  4. redshift/COSMOS_v11_uijk_0213_photo_UD.npz\n",
      "‚úÖ Charg√©: redshift/COSMOS_v11_uijk_0073_spec_UD.npz\n",
      "‚úÖ Charg√©: redshift/COSMOS_v11_uijk_0020_spec_D.npz\n",
      "‚úÖ Charg√©: redshift/COSMOS_v11_uijk_0001_photo_D.npz\n",
      "‚úÖ Charg√©: redshift/COSMOS_v11_uijk_0213_photo_UD.npz\n",
      "Total de fichiers COSMOS charg√©s: 4\n",
      "\n",
      "Cl√©s dans le fichier redshift/COSMOS_v11_uijk_0073_spec_UD.npz:\n",
      "  - cube\n",
      "    Shape de cube: (12, 64, 64, 9)\n",
      "  - info\n",
      "    Shape de info: (12,)\n",
      "  - flag\n",
      "    Shape de flag: (12, 9)\n",
      "\n",
      "Cl√©s dans le fichier redshift/COSMOS_v11_uijk_0020_spec_D.npz:\n",
      "  - cube\n",
      "    Shape de cube: (15, 64, 64, 9)\n",
      "  - info\n",
      "    Shape de info: (15,)\n",
      "  - flag\n",
      "    Shape de flag: (15, 9)\n",
      "\n",
      "Cl√©s dans le fichier redshift/COSMOS_v11_uijk_0001_photo_D.npz:\n",
      "  - cube\n",
      "    Shape de cube: (12054, 64, 64, 9)\n",
      "  - info\n",
      "    Shape de info: (12054,)\n",
      "  - flag\n",
      "    Shape de flag: (12054, 9)\n",
      "\n",
      "Cl√©s dans le fichier redshift/COSMOS_v11_uijk_0213_photo_UD.npz:\n",
      "  - cube\n",
      "    Shape de cube: (443, 64, 64, 9)\n",
      "  - info\n",
      "    Shape de info: (443,)\n",
      "  - flag\n",
      "    Shape de flag: (443, 9)\n",
      "\n",
      "Fichiers dans la derni√®re archive : ['cube', 'info', 'flag']\n",
      "Noms des colonnes info : ('ID', 'RA', 'DEC', 'TRACT', 'PATCH', 'MASK', 'FLAG_FIELD', 'EB_V', 'CLASS_STAR_HSC_I', 'u', 'uS', 'g', 'r', 'i', 'z', 'y', 'J', 'H', 'Ks', 'u_err', 'uS_err', 'g_err', 'r_err', 'i_err', 'z_err', 'y_err', 'J_err', 'H_err', 'Ks_err', 'ZPHOT', 'OBJ_TYPE', 'COMPACT', 'STAR_FORMING', 'ST_TRAIL', 'CLEAN', 'EBV', 'LABEL')\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. R√âCUP√âRATION ET CHARGEMENT\n",
    "# ==========================================\n",
    "\n",
    "path_pattern = os.path.join(\"redshift\", \"*.npz\")\n",
    "fichiers_npz = glob.glob(path_pattern)\n",
    "print(f\"\\nüìÇ Fichiers .npz trouv√©s ({len(fichiers_npz)}):\")\n",
    "for i, fichier in enumerate(fichiers_npz):\n",
    "    print(f\"  {i+1}. {fichier}\")\n",
    "\n",
    "cosmos_files = [f for f in fichiers_npz if \"COSMOS\" in f]\n",
    "print(f\"\\nFichiers COSMOS ({len(cosmos_files)}):\")\n",
    "for i, fichier in enumerate(cosmos_files):\n",
    "    print(f\"  {i+1}. {fichier}\")\n",
    "\n",
    "data_list = []\n",
    "for fichier in cosmos_files:\n",
    "    try:\n",
    "        data = np.load(fichier, allow_pickle=True)\n",
    "        data_list.append(data)\n",
    "        print(f\"‚úÖ Charg√©: {fichier}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur en chargeant {fichier}: {e}\")\n",
    "\n",
    "if not data_list:\n",
    "    raise ValueError(\"Aucun fichier COSMOS charg√©. Arr√™t du script.\")\n",
    "\n",
    "print(f\"Total de fichiers COSMOS charg√©s: {len(data_list)}\")\n",
    "\n",
    "for i, data in enumerate(data_list):\n",
    "    print(f\"\\nCl√©s dans le fichier {cosmos_files[i]}:\")\n",
    "    for key in data.keys():\n",
    "        print(f\"  - {key}\")\n",
    "        try:\n",
    "            print(f\"    Shape de {key}: {data[key].shape}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "bands_all = [\"u\",\"g\",\"r\",\"i\",\"z\",\"y\",\"J\",\"H\"]\n",
    "info = data_list[-1]['info'] # On prend l'info du dernier fichier charg√©\n",
    "print(f\"\\nFichiers dans la derni√®re archive : {data_list[-1].files}\")\n",
    "print(f\"Noms des colonnes info : {info.dtype.names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0edea2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. PR√âPARATION DES DONN√âES GLOBALES ---\n",
      "‚ö†Ô∏è ZSPEC introuvable dans un fichier. Remplissage avec des NaN.\n",
      "‚ö†Ô∏è ZSPEC introuvable dans un fichier. Remplissage avec des NaN.\n",
      "‚úÖ Magnitudes extraites : (12524, 8)\n",
      "‚úÖ ZSPEC (V√©rit√© Terrain / Test) extraits : (12524,)\n",
      "‚úÖ ZPHOT (Estimation / Train) extraits : (12524,)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. CONCAT√âNATION ET PR√âPARATION DES DONN√âES\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- 3. PR√âPARATION DES DONN√âES GLOBALES ---\")\n",
    "\n",
    "bands = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\", \"J\", \"H\"]\n",
    "\n",
    "mags_list = []\n",
    "zspec_list = []\n",
    "zphot_list = []\n",
    "cube_list = []\n",
    "\n",
    "for d in data_list:\n",
    "    info_array = d['info']\n",
    "    \n",
    "    mags = np.column_stack([info_array[b] for b in bands])\n",
    "    mags_list.append(mags)\n",
    "    zphot_list.append(info_array['ZPHOT'])\n",
    "    cube_list.append(d['cube'])\n",
    "    \n",
    "    # Extraction de ZSPEC avec protection NaN\n",
    "    try:\n",
    "        zspec_list.append(info_array['ZSPEC'])\n",
    "    except ValueError:\n",
    "        print(f\"‚ö†Ô∏è ZSPEC introuvable dans un fichier. Remplissage avec des NaN.\")\n",
    "        zspec_list.append(np.full(info_array.shape[0], np.nan))\n",
    "\n",
    "all_mags = np.vstack(mags_list)\n",
    "all_zphot = np.hstack(zphot_list)\n",
    "all_zspec = np.hstack(zspec_list)\n",
    "all_cubes = np.vstack(cube_list)\n",
    "\n",
    "print(f\"‚úÖ Magnitudes extraites : {all_mags.shape}\")\n",
    "print(f\"‚úÖ ZSPEC (V√©rit√© Terrain / Test) extraits : {all_zspec.shape}\")\n",
    "print(f\"‚úÖ ZPHOT (Estimation / Train) extraits : {all_zphot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1944bcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NETTOYAGE DES COLONNES MORTES (Variance nulle) ---\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# NETTOYAGE DES BANDES VIDES ET CR√âATION DU DATAFRAME\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- NETTOYAGE DES COLONNES MORTES (Variance nulle) ---\")\n",
    "# On identifie les colonnes de magnitudes qui sont pleines de 0 (pour √©viter les NaN dans le VIF)\n",
    "variances = np.var(all_mags, axis=0)\n",
    "colonnes_valides_idx = np.where(variances > 0)[0]\n",
    "colonnes_vides_idx = np.where(variances == 0)[0]\n",
    "\n",
    "if len(colonnes_vides_idx) > 0:\n",
    "    bandes_vides = [bands[i] for i in colonnes_vides_idx]\n",
    "    print(f\"‚ö†Ô∏è Alerte : Suppression des bandes vides ou constantes : {bandes_vides}\")\n",
    "    \n",
    "    # On met √† jour les matrices et les listes pour la suite du script\n",
    "    all_mags = all_mags[:, colonnes_valides_idx]\n",
    "    bands = [bands[i] for i in colonnes_valides_idx]\n",
    "\n",
    "# Cr√©ation du DataFrame finalis√© avec les bandes valides\n",
    "df_data = pd.DataFrame(all_mags, columns=bands)\n",
    "for i in range(len(bands) - 1):\n",
    "    col1, col2 = bands[i], bands[i+1]\n",
    "    df_data[f\"{col1}-{col2}\"] = df_data[col1] - df_data[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebc90ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INJECTION DES FEATURES DU R√âSEAU SSL ---\n",
      "Extraction des features sur cuda en cours...\n",
      "‚úÖ Features r√©seau extraites avec succ√®s ! Shape finale : (12524, 512)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. EXTRACTION DES FEATURES (R√âSEAU SSL)\n",
    "# ==========================================\n",
    "print(\"\\n--- INJECTION DES FEATURES DU R√âSEAU SSL ---\")\n",
    "\n",
    "# (N, 64, 64, 9) -> (N, 9, 64, 64)\n",
    "cubes_transposed = np.transpose(all_cubes, (0, 3, 1, 2))\n",
    "tensor_cubes = torch.FloatTensor(cubes_transposed)\n",
    "tensor_cubes = torch.nan_to_num(tensor_cubes, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "dataset = TensorDataset(tensor_cubes)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class ResNetAstroExtractor(nn.Module):\n",
    "    def __init__(self, architecture='resnet18'):\n",
    "        super().__init__()\n",
    "        if architecture == 'resnet18':\n",
    "            self.backbone = models.resnet18(weights=None)\n",
    "        elif architecture == 'resnet50':\n",
    "            self.backbone = models.resnet50(weights=None)\n",
    "        else:\n",
    "            raise ValueError(\"Architecture non support√©e.\")\n",
    "\n",
    "        self.backbone.conv1 = nn.Conv2d(9, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model_ssl = ResNetAstroExtractor(architecture='resnet18')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ssl = model_ssl.to(device)\n",
    "model_ssl.eval()\n",
    "\n",
    "print(f\"Extraction des features sur {device} en cours...\")\n",
    "features_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        inputs = batch[0].to(device)\n",
    "        outputs = model_ssl(inputs)\n",
    "        features_list.append(outputs.cpu().numpy())\n",
    "\n",
    "all_nn_features = np.vstack(features_list)\n",
    "print(f\"‚úÖ Features r√©seau extraites avec succ√®s ! Shape finale : {all_nn_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "356d8bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CALCUL DU VIF (Test de colin√©arit√©) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  VIF\n",
      "0        u  inf\n",
      "1        g  inf\n",
      "2        r  inf\n",
      "3        i  inf\n",
      "4        z  inf\n",
      "5        y  inf\n",
      "6        J  inf\n",
      "7        H  inf\n",
      "8      u-g  inf\n",
      "9      g-r  inf\n",
      "10     r-i  inf\n",
      "11     i-z  inf\n",
      "12     z-y  inf\n",
      "13     y-J  inf\n",
      "14     J-H  inf\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 5. CALCUL DU VIF (Redondance lin√©aire)\n",
    "# ==========================================\n",
    "print(\"\\n--- CALCUL DU VIF (Test de colin√©arit√©) ---\")\n",
    "def compute_vif(df):\n",
    "    df_clean = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    df_with_const = df_clean.copy()\n",
    "    df_with_const['const'] = 1.0\n",
    "    \n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = df_with_const.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df_with_const.values, i) for i in range(df_with_const.shape[1])]\n",
    "    \n",
    "    return vif_data[vif_data[\"Feature\"] != \"const\"]\n",
    "\n",
    "try:\n",
    "    vif_results = compute_vif(df_data)\n",
    "    print(vif_results)\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du calcul du VIF : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a997895c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AUTO-ENCODEUR : MAGNITUDES -> FEATURES R√âSEAU ---\n",
      "Epoch [10/50], MSE Loss : 0.9871\n",
      "Epoch [20/50], MSE Loss : 0.9798\n",
      "Epoch [30/50], MSE Loss : 0.9696\n",
      "Epoch [40/50], MSE Loss : 0.9354\n",
      "Epoch [50/50], MSE Loss : 0.8711\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. AUTO-ENCODEUR (Redondance Non-Lin√©aire)\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- AUTO-ENCODEUR : MAGNITUDES -> FEATURES R√âSEAU ---\")\n",
    "class RedundancyAE(nn.Module):\n",
    "    def __init__(self, in_features, target_features):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 16), nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32), nn.ReLU(),\n",
    "            nn.Linear(32, target_features)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_tensor = torch.FloatTensor(scaler_x.fit_transform(all_mags))\n",
    "Y_tensor = torch.FloatTensor(scaler_y.fit_transform(all_nn_features))\n",
    "\n",
    "model_ae = RedundancyAE(X_tensor.shape[1], Y_tensor.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_ae.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model_ae(X_tensor)\n",
    "    loss = criterion(predictions, Y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/50], MSE Loss : {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b4bcc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TESTS DE R√âGRESSION (Train: ZPHOT -> Test: ZSPEC) ---\n",
      "Galaxies pour l'ENTRA√éNEMENT (sur ZPHOT) : 12497\n",
      "Galaxies pour le TEST (sur ZSPEC)        : 27\n",
      "\n",
      "Entra√Ænement Mod√®le A (Magnitudes seules) sur ZPHOT...\n",
      "Entra√Ænement Mod√®le B (Magnitudes + Features NN) sur ZPHOT...\n",
      "\n",
      "--- R√âSULTATS (Pr√©dictions √©valu√©es contre ZSPEC) ---\n",
      "Magnitudes seules        : 0.4174\n",
      "Magnitudes + Features NN : 0.4054\n",
      "‚ö†Ô∏è Note : Tester sur un si petit nombre de ZSPEC peut rendre le score R2 tr√®s volatile.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. R√âGRESSION (Train: ZPHOT / Test: ZSPEC)\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- TESTS DE R√âGRESSION (Train: ZPHOT -> Test: ZSPEC) ---\")\n",
    "\n",
    "# 1. CR√âATION DES MASQUES LOGIQUES\n",
    "# On garde pour le TEST uniquement les galaxies ayant un ZSPEC valide\n",
    "mask_test_zspec = ~np.isnan(all_zspec) & (all_zspec > 0)\n",
    "\n",
    "# On garde pour l'ENTRA√éNEMENT le reste des galaxies, si elles ont un ZPHOT valide\n",
    "mask_train_zphot = (~mask_test_zspec) & (~np.isnan(all_zphot)) & (all_zphot > 0)\n",
    "\n",
    "# 2. S√âPARATION DES DONN√âES D'ENTRA√éNEMENT (Les ~12000 ZPHOT)\n",
    "X_train_mags = all_mags[mask_train_zphot]\n",
    "X_train_nn = all_nn_features[mask_train_zphot]\n",
    "X_train_combined = np.hstack((X_train_mags, X_train_nn))\n",
    "y_train_zphot = all_zphot[mask_train_zphot]\n",
    "\n",
    "# 3. S√âPARATION DES DONN√âES DE TEST (Les ~27 ZSPEC)\n",
    "X_test_mags = all_mags[mask_test_zspec]\n",
    "X_test_nn = all_nn_features[mask_test_zspec]\n",
    "X_test_combined = np.hstack((X_test_mags, X_test_nn))\n",
    "y_test_zspec = all_zspec[mask_test_zspec]\n",
    "\n",
    "print(f\"Galaxies pour l'ENTRA√éNEMENT (sur ZPHOT) : {len(y_train_zphot)}\")\n",
    "print(f\"Galaxies pour le TEST (sur ZSPEC)        : {len(y_test_zspec)}\")\n",
    "\n",
    "# 4. ENTRA√éNEMENT\n",
    "rf_mags = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "rf_combined = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(\"\\nEntra√Ænement Mod√®le A (Magnitudes seules) sur ZPHOT...\")\n",
    "rf_mags.fit(X_train_mags, y_train_zphot)\n",
    "\n",
    "print(\"Entra√Ænement Mod√®le B (Magnitudes + Features NN) sur ZPHOT...\")\n",
    "rf_combined.fit(X_train_combined, y_train_zphot)\n",
    "\n",
    "# 5. √âVALUATION\n",
    "score_mags = r2_score(y_test_zspec, rf_mags.predict(X_test_mags))\n",
    "score_combined = r2_score(y_test_zspec, rf_combined.predict(X_test_combined))\n",
    "\n",
    "print(\"\\n--- R√âSULTATS (Pr√©dictions √©valu√©es contre ZSPEC) ---\")\n",
    "print(f\"Magnitudes seules        : {score_mags:.4f}\")\n",
    "print(f\"Magnitudes + Features NN : {score_combined:.4f}\")\n",
    "\n",
    "if len(y_test_zspec) < 50:\n",
    "    print(\"‚ö†Ô∏è Note : Tester sur un si petit nombre de ZSPEC peut rendre le score R2 tr√®s volatile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a16406a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST DU 'R√âSULTAT PARFAIT' (Biais de Magnitude) ---\n",
      "-> R2 Score (Magnitudes Absolues -> SSL Features) : 0.0185\n",
      "-> R2 Score (Couleurs/Diff√©rences -> SSL Features) : 0.0114\n",
      "\n",
      "‚ö†Ô∏è R√âSULTAT MITIG√â : Le r√©seau encode des informations complexes non r√©ductibles aux magnitudes ou couleurs globales.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 8. TEST DU 'R√âSULTAT PARFAIT' (Biais de Magnitude)\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- TEST DU 'R√âSULTAT PARFAIT' (Biais de Magnitude) ---\")\n",
    "colonnes_mags = bands\n",
    "colonnes_couleurs = [c for c in df_data.columns if \"-\" in c]\n",
    "\n",
    "X_mags_only = df_data[colonnes_mags].values\n",
    "X_colors_only = df_data[colonnes_couleurs].values\n",
    "\n",
    "modele_test_mags = Ridge()\n",
    "modele_test_colors = Ridge()\n",
    "\n",
    "modele_test_mags.fit(X_mags_only, all_nn_features)\n",
    "pred_from_mags = modele_test_mags.predict(X_mags_only)\n",
    "r2_mags_to_ssl = r2_score(all_nn_features, pred_from_mags)\n",
    "\n",
    "modele_test_colors.fit(X_colors_only, all_nn_features)\n",
    "pred_from_colors = modele_test_colors.predict(X_colors_only)\n",
    "r2_colors_to_ssl = r2_score(all_nn_features, pred_from_colors)\n",
    "\n",
    "print(f\"-> R2 Score (Magnitudes Absolues -> SSL Features) : {r2_mags_to_ssl:.4f}\")\n",
    "print(f\"-> R2 Score (Couleurs/Diff√©rences -> SSL Features) : {r2_colors_to_ssl:.4f}\")\n",
    "\n",
    "if r2_colors_to_ssl > r2_mags_to_ssl + 0.1:\n",
    "    print(\"\\n‚úÖ R√âSULTAT PARFAIT ATTEINT !\")\n",
    "    print(\"Les features sont corr√©l√©es aux diff√©rences mais ont perdu l'information de la magnitude absolue.\")\n",
    "elif r2_mags_to_ssl > 0.8:\n",
    "    print(\"\\n‚ùå BIAIS PR√âSENT : Le r√©seau encode la magnitude absolue dans ses features.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è R√âSULTAT MITIG√â : Le r√©seau encode des informations complexes non r√©ductibles aux magnitudes ou couleurs globales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe85b41",
   "metadata": {},
   "source": [
    "# Sans valeurs aberrantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96c780fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.2. PR√âPARATION DES DONN√âES GLOBALES ---\n",
      "‚ö†Ô∏è ZSPEC introuvable dans un fichier. Remplissage avec des NaN.\n",
      "‚ö†Ô∏è ZSPEC introuvable dans un fichier. Remplissage avec des NaN.\n",
      "‚úÖ Magnitudes extraites : (12524, 8)\n",
      "‚úÖ ZSPEC (V√©rit√© Terrain / Test) extraits : (12524,)\n",
      "‚úÖ ZPHOT (Estimation / Train) extraits : (12524,)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3.2. CONCAT√âNATION ET PR√âPARATION DES DONN√âES\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- 3.2. PR√âPARATION DES DONN√âES GLOBALES ---\")\n",
    "\n",
    "bands = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\", \"J\", \"H\"]\n",
    "\n",
    "mags_list = []\n",
    "zspec_list = []\n",
    "zphot_list = []\n",
    "cube_list = []\n",
    "\n",
    "for d in data_list:\n",
    "    info_array = d['info']\n",
    "    \n",
    "    mags = np.column_stack([info_array[b] for b in bands])\n",
    "    mags_list.append(mags)\n",
    "    zphot_list.append(info_array['ZPHOT'])\n",
    "    cube_list.append(d['cube'])\n",
    "    \n",
    "    # Extraction de ZSPEC avec protection NaN\n",
    "    try:\n",
    "        zspec_list.append(info_array['ZSPEC'])\n",
    "    except ValueError:\n",
    "        print(f\"‚ö†Ô∏è ZSPEC introuvable dans un fichier. Remplissage avec des NaN.\")\n",
    "        zspec_list.append(np.full(info_array.shape[0], np.nan))\n",
    "\n",
    "all_mags = np.vstack(mags_list)\n",
    "all_zphot = np.hstack(zphot_list)\n",
    "all_zspec = np.hstack(zspec_list)\n",
    "all_cubes = np.vstack(cube_list)\n",
    "\n",
    "print(f\"‚úÖ Magnitudes extraites : {all_mags.shape}\")\n",
    "print(f\"‚úÖ ZSPEC (V√©rit√© Terrain / Test) extraits : {all_zspec.shape}\")\n",
    "print(f\"‚úÖ ZPHOT (Estimation / Train) extraits : {all_zphot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7084e69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- REMPLACEMENT DES VALEURS ABERRANTES PAR 0 ---\n",
      "‚úÖ Valeurs aberrantes remplac√©es par 0 (Les ZSPEC manquants sont pr√©serv√©s en NaN).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- REMPLACEMENT DES VALEURS ABERRANTES PAR 0 ---\")\n",
    "mask_physique_mags = (all_mags < 0) | (all_mags > 40)\n",
    "all_mags[mask_physique_mags] = 0\n",
    "\n",
    "z_scores_mags = np.abs(stats.zscore(all_mags, nan_policy='omit'))\n",
    "all_mags[z_scores_mags > 3] = 0\n",
    "\n",
    "# Filtre avec protection pour ignorer les NaN lors de la comparaison\n",
    "with np.errstate(invalid='ignore'):\n",
    "    mask_physique_zspec = (all_zspec < 0) | (all_zspec > 6)\n",
    "    mask_physique_zphot = (all_zphot < 0) | (all_zphot > 6)\n",
    "\n",
    "# On ne met √† 0 que les valeurs aberrantes. Les NaN restent des NaN.\n",
    "all_zspec[mask_physique_zspec] = 0\n",
    "all_zphot[mask_physique_zphot] = 0\n",
    "\n",
    "print(\"‚úÖ Valeurs aberrantes remplac√©es par 0 (Les ZSPEC manquants sont pr√©serv√©s en NaN).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fdf2721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NETTOYAGE DES COLONNES MORTES (Variance nulle) ---\n",
      "‚ö†Ô∏è Alerte : Suppression des bandes vides ou constantes : ['J', 'H']\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3.3. NETTOYAGE DES BANDES VIDES ET CR√âATION DU DATAFRAME\n",
    "# ==========================================\n",
    "print(\"\\n--- NETTOYAGE DES COLONNES MORTES (Variance nulle) ---\")\n",
    "# On identifie les colonnes de magnitudes qui sont pleines de 0 (pour √©viter les NaN dans le VIF)\n",
    "variances = np.var(all_mags, axis=0)\n",
    "colonnes_valides_idx = np.where(variances > 0)[0]\n",
    "colonnes_vides_idx = np.where(variances == 0)[0]\n",
    "\n",
    "if len(colonnes_vides_idx) > 0:\n",
    "    bandes_vides = [bands[i] for i in colonnes_vides_idx]\n",
    "    print(f\"‚ö†Ô∏è Alerte : Suppression des bandes vides ou constantes : {bandes_vides}\")\n",
    "    \n",
    "    # On met √† jour les matrices et les listes pour la suite du script\n",
    "    all_mags = all_mags[:, colonnes_valides_idx]\n",
    "    bands = [bands[i] for i in colonnes_valides_idx]\n",
    "\n",
    "# Cr√©ation du DataFrame finalis√© avec les bandes valides\n",
    "df_data = pd.DataFrame(all_mags, columns=bands)\n",
    "for i in range(len(bands) - 1):\n",
    "    col1, col2 = bands[i], bands[i+1]\n",
    "    df_data[f\"{col1}-{col2}\"] = df_data[col1] - df_data[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f623b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INJECTION DES FEATURES DU R√âSEAU SSL ---\n",
      "Extraction des features sur cuda en cours...\n",
      "‚úÖ Features r√©seau extraites avec succ√®s ! Shape finale : (12524, 512)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. EXTRACTION DES FEATURES (R√âSEAU SSL)\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- INJECTION DES FEATURES DU R√âSEAU SSL ---\")\n",
    "\n",
    "# (N, 64, 64, 9) -> (N, 9, 64, 64)\n",
    "cubes_transposed = np.transpose(all_cubes, (0, 3, 1, 2))\n",
    "tensor_cubes = torch.FloatTensor(cubes_transposed)\n",
    "tensor_cubes = torch.nan_to_num(tensor_cubes, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "dataset = TensorDataset(tensor_cubes)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class ResNetAstroExtractor(nn.Module):\n",
    "    def __init__(self, architecture='resnet18'):\n",
    "        super().__init__()\n",
    "        if architecture == 'resnet18':\n",
    "            self.backbone = models.resnet18(weights=None)\n",
    "        elif architecture == 'resnet50':\n",
    "            self.backbone = models.resnet50(weights=None)\n",
    "        else:\n",
    "            raise ValueError(\"Architecture non support√©e.\")\n",
    "\n",
    "        self.backbone.conv1 = nn.Conv2d(9, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model_ssl = ResNetAstroExtractor(architecture='resnet18')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ssl = model_ssl.to(device)\n",
    "model_ssl.eval()\n",
    "\n",
    "print(f\"Extraction des features sur {device} en cours...\")\n",
    "features_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        inputs = batch[0].to(device)\n",
    "        outputs = model_ssl(inputs)\n",
    "        features_list.append(outputs.cpu().numpy())\n",
    "\n",
    "all_nn_features = np.vstack(features_list)\n",
    "print(f\"‚úÖ Features r√©seau extraites avec succ√®s ! Shape finale : {all_nn_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d9814a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CALCUL DU VIF (Test de colin√©arit√©) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  VIF\n",
      "0        u  inf\n",
      "1        g  inf\n",
      "2        r  inf\n",
      "3        i  inf\n",
      "4        z  inf\n",
      "5        y  inf\n",
      "6      u-g  inf\n",
      "7      g-r  inf\n",
      "8      r-i  inf\n",
      "9      i-z  inf\n",
      "10     z-y  inf\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 5. CALCUL DU VIF (Redondance lin√©aire)\n",
    "# ==========================================\n",
    "print(\"\\n--- CALCUL DU VIF (Test de colin√©arit√©) ---\")\n",
    "def compute_vif(df):\n",
    "    df_clean = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    df_with_const = df_clean.copy()\n",
    "    df_with_const['const'] = 1.0\n",
    "    \n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = df_with_const.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df_with_const.values, i) for i in range(df_with_const.shape[1])]\n",
    "    \n",
    "    return vif_data[vif_data[\"Feature\"] != \"const\"]\n",
    "\n",
    "try:\n",
    "    vif_results = compute_vif(df_data)\n",
    "    print(vif_results)\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du calcul du VIF : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1d2b3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AUTO-ENCODEUR : MAGNITUDES -> FEATURES R√âSEAU ---\n",
      "Epoch [10/50], MSE Loss : 0.9999\n",
      "Epoch [20/50], MSE Loss : 0.9939\n",
      "Epoch [30/50], MSE Loss : 0.9754\n",
      "Epoch [40/50], MSE Loss : 0.9162\n",
      "Epoch [50/50], MSE Loss : 0.7729\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. AUTO-ENCODEUR (Redondance Non-Lin√©aire)\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- AUTO-ENCODEUR : MAGNITUDES -> FEATURES R√âSEAU ---\")\n",
    "class RedundancyAE(nn.Module):\n",
    "    def __init__(self, in_features, target_features):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 16), nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32), nn.ReLU(),\n",
    "            nn.Linear(32, target_features)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_tensor = torch.FloatTensor(scaler_x.fit_transform(all_mags))\n",
    "Y_tensor = torch.FloatTensor(scaler_y.fit_transform(all_nn_features))\n",
    "\n",
    "model_ae = RedundancyAE(X_tensor.shape[1], Y_tensor.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_ae.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model_ae(X_tensor)\n",
    "    loss = criterion(predictions, Y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/50], MSE Loss : {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8196d168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TESTS DE R√âGRESSION (Train: ZPHOT -> Test: ZSPEC) ---\n",
      "Galaxies pour l'ENTRA√éNEMENT (sur ZPHOT) : 12497\n",
      "Galaxies pour le TEST (sur ZSPEC)        : 27\n",
      "\n",
      "Entra√Ænement Mod√®le A (Magnitudes seules) sur ZPHOT...\n",
      "Entra√Ænement Mod√®le B (Magnitudes + Features NN) sur ZPHOT...\n",
      "\n",
      "--- R√âSULTATS (Pr√©dictions √©valu√©es contre ZSPEC) ---\n",
      "Magnitudes seules        : 0.4082\n",
      "Magnitudes + Features NN : 0.4113\n",
      "‚ö†Ô∏è Note : Tester sur un si petit nombre de ZSPEC peut rendre le score R2 tr√®s volatile.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. R√âGRESSION (Train: ZPHOT / Test: ZSPEC)\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- TESTS DE R√âGRESSION (Train: ZPHOT -> Test: ZSPEC) ---\")\n",
    "\n",
    "# 1. CR√âATION DES MASQUES LOGIQUES\n",
    "# On garde pour le TEST uniquement les galaxies ayant un ZSPEC valide\n",
    "mask_test_zspec = ~np.isnan(all_zspec) & (all_zspec > 0)\n",
    "\n",
    "# On garde pour l'ENTRA√éNEMENT le reste des galaxies, si elles ont un ZPHOT valide\n",
    "mask_train_zphot = (~mask_test_zspec) & (~np.isnan(all_zphot)) & (all_zphot > 0)\n",
    "\n",
    "# 2. S√âPARATION DES DONN√âES D'ENTRA√éNEMENT (Les ~12000 ZPHOT)\n",
    "X_train_mags = all_mags[mask_train_zphot]\n",
    "X_train_nn = all_nn_features[mask_train_zphot]\n",
    "X_train_combined = np.hstack((X_train_mags, X_train_nn))\n",
    "y_train_zphot = all_zphot[mask_train_zphot]\n",
    "\n",
    "# 3. S√âPARATION DES DONN√âES DE TEST (Les ~27 ZSPEC)\n",
    "X_test_mags = all_mags[mask_test_zspec]\n",
    "X_test_nn = all_nn_features[mask_test_zspec]\n",
    "X_test_combined = np.hstack((X_test_mags, X_test_nn))\n",
    "y_test_zspec = all_zspec[mask_test_zspec]\n",
    "\n",
    "print(f\"Galaxies pour l'ENTRA√éNEMENT (sur ZPHOT) : {len(y_train_zphot)}\")\n",
    "print(f\"Galaxies pour le TEST (sur ZSPEC)        : {len(y_test_zspec)}\")\n",
    "\n",
    "# 4. ENTRA√éNEMENT\n",
    "rf_mags = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "rf_combined = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(\"\\nEntra√Ænement Mod√®le A (Magnitudes seules) sur ZPHOT...\")\n",
    "rf_mags.fit(X_train_mags, y_train_zphot)\n",
    "\n",
    "print(\"Entra√Ænement Mod√®le B (Magnitudes + Features NN) sur ZPHOT...\")\n",
    "rf_combined.fit(X_train_combined, y_train_zphot)\n",
    "\n",
    "# 5. √âVALUATION\n",
    "score_mags = r2_score(y_test_zspec, rf_mags.predict(X_test_mags))\n",
    "score_combined = r2_score(y_test_zspec, rf_combined.predict(X_test_combined))\n",
    "\n",
    "print(\"\\n--- R√âSULTATS (Pr√©dictions √©valu√©es contre ZSPEC) ---\")\n",
    "print(f\"Magnitudes seules        : {score_mags:.4f}\")\n",
    "print(f\"Magnitudes + Features NN : {score_combined:.4f}\")\n",
    "\n",
    "if len(y_test_zspec) < 50:\n",
    "    print(\"‚ö†Ô∏è Note : Tester sur un si petit nombre de ZSPEC peut rendre le score R2 tr√®s volatile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b750af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST DU 'R√âSULTAT PARFAIT' (Biais de Magnitude) ---\n",
      "-> R2 Score (Magnitudes Absolues -> SSL Features) : 0.0030\n",
      "-> R2 Score (Couleurs/Diff√©rences -> SSL Features) : 0.0001\n",
      "\n",
      "‚ö†Ô∏è R√âSULTAT MITIG√â : Le r√©seau encode des informations complexes non r√©ductibles aux magnitudes ou couleurs globales.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 8.2. TEST DU 'R√âSULTAT PARFAIT' (Biais de Magnitude)\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- TEST DU 'R√âSULTAT PARFAIT' (Biais de Magnitude) ---\")\n",
    "colonnes_mags = bands\n",
    "colonnes_couleurs = [c for c in df_data.columns if \"-\" in c]\n",
    "\n",
    "X_mags_only = df_data[colonnes_mags].values\n",
    "X_colors_only = df_data[colonnes_couleurs].values\n",
    "\n",
    "modele_test_mags = Ridge()\n",
    "modele_test_colors = Ridge()\n",
    "\n",
    "modele_test_mags.fit(X_mags_only, all_nn_features)\n",
    "pred_from_mags = modele_test_mags.predict(X_mags_only)\n",
    "r2_mags_to_ssl = r2_score(all_nn_features, pred_from_mags)\n",
    "\n",
    "modele_test_colors.fit(X_colors_only, all_nn_features)\n",
    "pred_from_colors = modele_test_colors.predict(X_colors_only)\n",
    "r2_colors_to_ssl = r2_score(all_nn_features, pred_from_colors)\n",
    "\n",
    "print(f\"-> R2 Score (Magnitudes Absolues -> SSL Features) : {r2_mags_to_ssl:.4f}\")\n",
    "print(f\"-> R2 Score (Couleurs/Diff√©rences -> SSL Features) : {r2_colors_to_ssl:.4f}\")\n",
    "\n",
    "if r2_colors_to_ssl > r2_mags_to_ssl + 0.1:\n",
    "    print(\"\\n‚úÖ R√âSULTAT PARFAIT ATTEINT !\")\n",
    "    print(\"Les features sont corr√©l√©es aux diff√©rences mais ont perdu l'information de la magnitude absolue.\")\n",
    "elif r2_mags_to_ssl > 0.8:\n",
    "    print(\"\\n‚ùå BIAIS PR√âSENT : Le r√©seau encode la magnitude absolue dans ses features.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è R√âSULTAT MITIG√â : Le r√©seau encode des informations complexes non r√©ductibles aux magnitudes ou couleurs globales.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
